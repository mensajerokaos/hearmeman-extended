{
  "name": "SteadyDancer Dance Animation",
  "description": "Generate dance videos from reference images using SteadyDancer I2V model with DWPose motion extraction. Best for datacenter GPUs (A100 80GB).",
  "nodes": [
    {
      "id": "1",
      "class_type": "LoadImage",
      "inputs": {
        "image": "reference_character.png",
        "choose_file_to_upload": "reference_character.png"
      }
    },
    {
      "id": "2",
      "class_type": "LoadVideo",
      "inputs": {
        "video": "driving_dance.mp4",
        "frame_count": 16,
        "fps": 25,
        "force_rate": 25,
        "skip_first_frames": 0
      }
    },
    {
      "id": "3",
      "class_type": "DWPreprocessor",
      "inputs": {
        "image": "2",
        "detect_hand": true,
        "detect_body": true,
        "detect_face": true,
        "resolution": 512,
        "pose_threshold": 0.05
      },
      "name": "DWPose Extraction"
    },
    {
      "id": "4",
      "class_type": "Wan_LoadDiffusionModel",
      "inputs": {
        "model_name": "Wan21_SteadyDancer_fp8.safetensors",
        "weight_dtype": "fp8"
      },
      "name": "Load SteadyDancer Model"
    },
    {
      "id": "5",
      "class_type": "Wan_LoadVAE",
      "inputs": {
        "vae_name": "wan_2.1_vae.safetensors"
      },
      "name": "Load VAE"
    },
    {
      "id": "6",
      "class_type": "Wan_ReferenceAttention",
      "inputs": {
        "reference_image": "1",
        "conditioning_strength": 0.8,
        "reference_type": "image",
        "scale": 1.0,
        "do_classifier_free_guidance": false
      },
      "name": "Reference Attention (Identity)"
    },
    {
      "id": "7",
      "class_type": "Wan_CrossFrameAttention",
      "inputs": {
        "driving_video": "2",
        "frame_count": 16,
        "motion_strength": 1.0
      },
      "name": "Cross-Frame Attention (Motion)"
    },
    {
      "id": "8",
      "class_type": "Wan_KSampler",
      "inputs": {
        "model": "4",
        "vae": "5",
        "positive": ["6", 0],
        "negative": [["CLIPTextEncode", 0], 0],
        "latent_image": [["EmptyLatentImage", 0], 0],
        "seed": 106060,
        "steps": 50,
        "cfg": 5.0,
        "sampler_name": "euler",
        "scheduler": "simple",
        "denoise": 1.0
      },
      "name": "KSampler (Vanilla)"
    },
    {
      "id": "9",
      "class_type": "VAEDecode",
      "inputs": {
        "samples": ["8", 0],
        "vae": "5"
      }
    },
    {
      "id": "10",
      "class_type": "SaveVideo",
      "inputs": {
        "images": "9",
        "filename_prefix": "steadydancer_dance_vanilla",
        "fps": 25,
        "format": "mp4h264",
        "pix_fmt": "yuv420p",
        "crf": 23,
        "audio_path": "",
        "output_format": "mp4"
      },
      "name": "Save Video"
    },
    {
      "id": "11",
      "class_type": "CLIPTextEncode",
      "inputs": {
        "text": "A person dancing with smooth, natural movements, high quality, detailed",
        "clip": [["Wan_LoadDiffusionModel", 4], 2]
      },
      "name": "Positive Prompt"
    },
    {
      "id": "12",
      "class_type": "CLIPTextEncode",
      "inputs": {
        "text": "blurry, distorted, low quality, artifacts, jittery motion",
        "clip": [["Wan_LoadDiffusionModel", 4], 2]
      },
      "name": "Negative Prompt"
    },
    {
      "id": "13",
      "class_type": "EmptyLatentImage",
      "inputs": {
        "width": 512,
        "height": 512,
        "batch_size": 1
      },
      "name": "Latent Image (512x512)"
    }
  ],
  "links": [
    ["1", "6", "reference_image"],
    ["2", "3", "image"],
    ["2", "7", "driving_video"],
    ["3", "7", "conditioning"],
    ["4", "8", "model"],
    ["5", "8", "vae"],
    ["5", "9", "vae"],
    ["6", "8", "positive"],
    ["7", "8", "conditioning"],
    ["8", "9", "samples"],
    ["9", "10", "images"],
    ["11", "8", "positive"],
    ["12", "8", "negative"],
    ["13", "8", "latent_image"]
  ],
  "groups": [],
  "config": {
    "extra": {},
    "DL_type": "StableDiffusion",
    "StableDiffusion": {
      "model": "Wan2.1-I2V",
      "version": "2.1"
    }
  },
  "workflow_version": "1.0"
}
